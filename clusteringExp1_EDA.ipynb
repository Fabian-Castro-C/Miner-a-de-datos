{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mp_api.client import MPRester\n",
    "from matminer.data_retrieval.retrieve_MP import MPDataRetrieval\n",
    "from matminer.featurizers.base import MultipleFeaturizer, StackedFeaturizer\n",
    "from matminer.featurizers import composition as cf\n",
    "\n",
    "# Conectar con la base de datos de materials project usando la API de pymatgen\n",
    "# Reemplaza \"YOUR_API_KEY\" con tu clave de API obtenida desde el sitio web de materials project\n",
    "mpr = MPRester(\"Q4KseBQeiCIFmpyIzcxTaWeQ0DVWzyZf\")\n",
    "\n",
    "# Obtener los datos de materiales que quieres analizar\n",
    "# En este ejemplo, se obtienen los datos de los óxidos binarios con una energía de formación menor que -1 eV/átomo\n",
    "# Se seleccionan las propiedades: identificador del material (material_id), fórmula reducida (reduced_cell_formula), energía de formación (formation_energy_per_atom) y volumen (volume)\n",
    "docs = mpr.summary.search(elements=[\"Si\"], band_gap=(0.0, 1.05),fields=[\"material_id\", \"composition\",\"reduced_cell_formula\", \"formation_energy_per_atom\", \"volume\"])\n",
    "\n",
    "# Convertir los resultados en un dataframe\n",
    "df = pd.DataFrame([material.__dict__ for material in docs])\n",
    "\n",
    "# df = pd.read_csv('todo_mat')\n",
    "# df = df[0:50]\n",
    "\n",
    "# Aplicar algún método de reducción de dimensionalidad o selección de características para simplificar los datos\n",
    "# En este ejemplo, se usa la función auto_featurize de matminer para generar automáticamente características a partir de la composición química\n",
    "# Se usan las siguientes clases de características: ElementProperty, Stoichiometry, ValenceOrbital, IonProperty y ElementFraction\n",
    "feature_classes = [cf.ElementProperty.from_preset(\"magpie\"), cf.Stoichiometry(), cf.ValenceOrbital(props=[\"avg\"]), cf.IonProperty(), cf.ElementFraction()]\n",
    "featurizer = MultipleFeaturizer(feature_classes)\n",
    "X = featurizer.fit_transform(df['composition'])\n",
    "\n",
    "X_df = pd.DataFrame(X)\n",
    "X_df = X_df.dropna(axis=1) # Eliminar las columnas con valores nulos\n",
    "\n",
    "# Elegir un algoritmo de clustering adecuado para los datos\n",
    "# En este ejemplo, se usa el algoritmo KMeans de sklearn para agrupar los datos en k grupos según su similitud\n",
    "# Se elige el valor de k usando el método del codo, que consiste en variar el valor de k y observar el cambio en la suma de cuadrados dentro de los grupos (inertia)\n",
    "ks = range(2, 11) # Probar valores de k entre 2 y 10\n",
    "inertias = [] # Lista para guardar los valores de inertia para cada k\n",
    "for k in ks:\n",
    "    # Crear el modelo de KMeans con k grupos\n",
    "    model = KMeans(n_clusters=k, random_state=0)\n",
    "    # Entrenar el modelo con los datos\n",
    "    model.fit(X_df)\n",
    "    # Añadir el valor de inertia a la lista\n",
    "    inertias.append(model.inertia_)\n",
    "\n",
    "# Graficar los valores de k e inertia\n",
    "plt.plot(ks, inertias, \"-o\")\n",
    "plt.xlabel(\"Número de grupos (k)\")\n",
    "plt.ylabel(\"Suma de cuadrados dentro de los grupos (inertia)\")\n",
    "plt.title(\"Método del codo para KMeans\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Según la gráfica, se observa que el valor óptimo de k es 6, ya que a partir de ese punto la curva se suaviza\n",
    "# Por lo tanto, se crea el modelo de KMeans con k=6 y se obtienen las etiquetas de los grupos asignados a cada material\n",
    "models = []\n",
    "labels_all = []\n",
    "for i in range(3,9):\n",
    "    model = KMeans(n_clusters=i, random_state=0)\n",
    "    model.fit(X_df)\n",
    "    labels = model.labels_\n",
    "    models.append(model)\n",
    "    labels_all.append(labels)\n",
    "\n",
    "# Evaluar el resultado del clustering usando alguna medida de calidad\n",
    "# En este ejemplo, se usan el coeficiente de silueta y el índice Davies-Bouldin, que miden la cohesión y la separación de los grupos\n",
    "# El coeficiente de silueta varía entre -1 y 1, siendo 1 el mejor valor posible\n",
    "# El índice Davies-Bouldin varía entre 0 e infinito, siendo 0 el mejor valor posible\n",
    "for i in range(0,len(labels_all)):\n",
    "    silhouette = silhouette_score(X_df, labels_all[i])\n",
    "    davies_bouldin = davies_bouldin_score(X_df, labels_all[i])\n",
    "    print(f\"Coeficiente de silueta: {silhouette:.2f} con {i+3} clusters\")\n",
    "    print(f\"Índice Davies-Bouldin: {davies_bouldin:.2f} con {i+3} clusters\")\n",
    "\n",
    "# Visualizar el resultado del clustering usando alguna técnica de proyección o gráfica\n",
    "# En este ejemplo, se usa el análisis de componentes principales (PCA) para reducir la dimensionalidad de los datos a dos dimensiones y graficar los puntos con colores según su grupo\n",
    "for i in range(0,len(labels_all)):\n",
    "    pca = PCA(n_components=3)\n",
    "    X_pca = pca.fit_transform(X_df)\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels_all[i], cmap=\"Set1\")\n",
    "    plt.xlabel(\"Componente principal 1\")\n",
    "    plt.ylabel(\"Componente principal 2\")\n",
    "    plt.title(\"Clustering de la base de datos de materials project usando PCA\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sim_matrix(features, labels):\n",
    "    useful_labels = labels >= 0\n",
    "\n",
    "    # primero ordenamos los datos en base al cluster que pertencen\n",
    "    indices = np.argsort(labels[useful_labels])\n",
    "    sorted_features = features[useful_labels][indices]\n",
    "\n",
    "    # calculamos las distancias entre todos los puntos\n",
    "    d = euclidean_distances(sorted_features, sorted_features)\n",
    "    return d\n",
    "\n",
    "def plot(data, model, is_model = True):\n",
    "    if is_model:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,5))\n",
    "\n",
    "        fig.suptitle(f\"{model.__class__.__name__}\")\n",
    "\n",
    "        ax1.scatter(data[:,0], data[:,1], c=model.labels_)\n",
    "\n",
    "        dist = sim_matrix(data, model.labels_)\n",
    "        im = ax2.imshow(dist, cmap=\"jet\")\n",
    "        fig.colorbar(im, ax=ax2)\n",
    "    else:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,5))\n",
    "\n",
    "        fig.suptitle('Clustering Jerárquico')\n",
    "\n",
    "        ax1.scatter(data[:,0], data[:,1], c = model)\n",
    "\n",
    "        dist = sim_matrix(data, model)\n",
    "        im = ax2.imshow(dist, cmap=\"jet\")\n",
    "        fig.colorbar(im, ax=ax2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(X_pca, models[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(models[1].labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With X_pca data and models[1] (4 clusters), we get the characteristics of each point in each cluster\n",
    "# We can use this information to get the materials in each cluster\n",
    "df['cluster'] = models[1].labels_ # Add the cluster labels to the dataframe\n",
    "df[df['cluster'] == 0] # Get the materials in cluster 0\n",
    "# df[df['cluster'] == 1] # Get the materials in cluster 1\n",
    "# df[df['cluster'] == 2] # Get the materials in cluster 2\n",
    "# df[df['cluster'] == 3] # Get the materials in cluster 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MD_MP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
